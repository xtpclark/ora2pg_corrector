= Ora2Pg AI Corrector
:toc:
:source-highlighter: highlight.js

A smart web interface to accelerate Oracle to PostgreSQL migrations by automating the correction and validation of translated SQL code.

== Overview

Migrating from Oracle to PostgreSQL often involves using tools like `ora2pg` to perform the initial code translation. While `ora2pg` provides an excellent starting point, the generated SQL frequently requires manual corrections and extensive testing to ensure compatibility and correctness in a live PostgreSQL environment.

The Ora2Pg AI Corrector is designed to streamline this crucial "last mile" of the migration process. It provides a web-based, multi-client workspace where developers can use a powerful AI engine to automatically correct translated SQL and then validate it against a live PostgreSQL database using a unique "self-healing" engine.

== Key Features

* **Web-based, Multi-Client Workspace:** Manage multiple migration projects or clients, each with its own set of configurations for AI providers, database connections, and `ora2pg` settings.
* **AI-Powered SQL Correction:** A dual-editor view allows you to paste Oracle SQL and get an AI-generated PostgreSQL equivalent that corrects for common syntax and function differences (e.g., `NVL` to `COALESCE`, `VARCHAR2` to `VARCHAR`).
* **Intelligent Validation Engine:** This is the core of the application, designed to test the corrected SQL against a real database and automatically resolve schema dependencies.
** Proactive Schema Generation:** For `SELECT` queries, the engine first parses the SQL to identify all required tables. It then makes a single, consolidated call to the AI to generate the DDL for all missing tables at once, drastically speeding up the setup process.
** Reactive Self-Healing:** If an error occurs, the engine attempts to fix it automatically:
*** On-the-fly DDL:** Catches `relation "..." does not exist` errors (e.g., from `FOREIGN KEY` references) and asks the AI to generate the DDL for the specific missing object before retrying.
*** AI Query Correction:** Catches other errors (e.g., syntax errors, missing columns) and asks the AI to fix the query itself before retrying.
* **Fine-Grained User Control:** Two checkboxes, `Clean Slate` and `Auto-create Tables`, give the user complete control over the validation environment, enabling workflows for initial discovery, iterative development, and validation against pre-existing "golden" schemas.

== How It Works: The Typical Workflow

. **Load Oracle SQL:** A user selects their client/project and pastes the Oracle SQL generated by `ora2pg` (or written by hand) into the left-side editor.
. **Correct with AI:** The user clicks "Correct with AI". The application sends the Oracle code to the configured AI model and displays the translated PostgreSQL code in the right-side editor.
. **Review & Refine:** The user can review the AI's translation and make manual edits if necessary.
. **Validate:** The user configures the `Clean Slate` and `Auto-create Tables` options and clicks "Validate". The application attempts to execute the PostgreSQL code against the validation database, using the self-healing engine to resolve any schema or syntax issues.
. **Save:** Once validated, the user can save the final, corrected, and verified PostgreSQL code.

== Getting Started

=== Prerequisites

* Docker
* Docker Compose

=== Installation & Running

. Clone the repository:
+
[source,bash]
----
git clone <your-repository-url>
cd ora2pg-ai-corrector
----
. Create a `.env` file by copying the example. This file will store your application secrets and database configurations.
+
[source,bash]
----
cp .env.example .env
----
. Edit the `.env` file with your specific settings:
+
[source,text]
----
# For the application's internal database (SQLite or Postgres)
# DB_BACKEND=sqlite
# PG_DSN_CONFIG=postgresql://user:pass@host:port/app_db

# For the PostgreSQL database used for validation
VALIDATION_PG_DSN=postgresql://user:pass@host:port/validation_db

# Application secrets
APP_SECRET_KEY=your_super_secret_key
APP_ENCRYPTION_KEY=your_32_byte_fernet_encryption_key
----
. Build and run the application using Docker Compose:
+
[source,bash]
----
docker-compose up --build
----
. Access the web interface at `http://localhost:8000`.

== Configuration

* **AI Providers (`ai_config/ai_providers.json`):** Add or modify AI provider details in this file. The application will load these into its database on startup.
* **Ora2Pg Options (`ora2pg_config/default.cfg`):** The contents of this file are used to populate the available Ora2Pg configuration options in the UI's settings page.

== One-Click DDL Migration

The application now supports automated end-to-end DDL migration with a single click. This feature discovers Oracle schema objects, exports them via Ora2Pg, validates against PostgreSQL, and uses AI only when needed for error correction.

=== How It Works

[source,text]
----
Oracle Schema → Discovery → Ora2Pg Export → Validate → [AI Fix if needed] → Done
                  │              │              │              │
                  ▼              ▼              ▼              ▼
            SQL*Plus      TABLE, VIEW,    Execute on      Self-healing
            ALL_OBJECTS   PROCEDURE...    PostgreSQL      retry loop
----

**Key Optimization:** AI tokens are only spent when validation fails. If Ora2Pg output validates successfully (which is common), no AI calls are made.

=== Using the GUI

. Select your client from the dropdown
. Click the **"Start One-Click Migration"** button in the Migration pane
. Configure options:
** **Auto-create DDL:** Automatically create missing dependency tables (recommended)
** **Clean Slate:** Drop existing tables before validation (use for fresh starts)
. Click **"Start Migration"**
. Monitor progress via the progress bar and phase indicator
. Review results showing successful/failed files

=== Using the API (curl)

==== Step 1: Create and Configure a Client

[source,bash]
----
# Create a new client
curl -X POST http://localhost:8000/api/clients \
  -H "Content-Type: application/json" \
  -d '{"client_name": "My_Migration_Project"}'

# Configure Oracle connection, validation database, and AI provider
curl -X POST http://localhost:8000/api/client/1/config \
  -H "Content-Type: application/json" \
  -d '{
    "oracle_dsn": "dbi:Oracle:host=oracle-server;service_name=ORCL;port=1521",
    "oracle_user": "schema_owner",
    "oracle_pwd": "password",
    "schema": "MY_SCHEMA",
    "pg_version": "16",
    "validation_pg_dsn": "dbname=staging user=postgres password=pass host=localhost port=5432",
    "ai_provider": "Anthropic Claude",
    "ai_endpoint": "https://api.anthropic.com/v1/",
    "ai_model": "claude-sonnet-4-20250514",
    "ai_api_key": "sk-ant-..."
  }'
----

==== Step 2: Start the Migration

[source,bash]
----
# Start async migration (recommended for large schemas)
curl -X POST http://localhost:8000/api/client/1/start_migration \
  -H "Content-Type: application/json" \
  -d '{"auto_create_ddl": true, "clean_slate": false}'

# Response:
# {"message":"Migration started","poll_url":"/api/client/1/migration_status","status":"running"}
----

==== Step 3: Poll for Status

[source,bash]
----
# Check progress (poll every few seconds)
curl http://localhost:8000/api/client/1/migration_status

# Response while running:
# {
#   "status": "running",
#   "phase": "validating",
#   "total_objects": 10,
#   "processed_objects": 5,
#   "successful": 4,
#   "failed": 0,
#   "errors": []
# }

# Response when complete:
# {
#   "status": "completed",
#   "successful": 10,
#   "failed": 0,
#   "files": [
#     {"file_id": 1, "filename": "output_table.sql", "status": "validated"},
#     {"file_id": 2, "filename": "output_view.sql", "status": "validated"},
#     ...
#   ]
# }
----

==== Alternative: Synchronous Migration

For smaller schemas, you can run the migration synchronously (blocks until complete):

[source,bash]
----
curl -X POST http://localhost:8000/api/client/1/run_migration_sync \
  -H "Content-Type: application/json" \
  -d '{"auto_create_ddl": true}'
----

=== Migration Options

[cols="1,1,3"]
|===
|Option |Default |Description

|`auto_create_ddl`
|`true`
|Automatically generate and apply DDL for missing dependency tables (e.g., foreign key references)

|`clean_slate`
|`false`
|Drop existing tables before validation. Use when starting fresh or re-running migrations.

|`object_types`
|All supported
|Limit migration to specific types: `["TABLE", "VIEW", "PROCEDURE"]`
|===

=== Supported Object Types

The migration processes objects in dependency order:

. TYPE
. SEQUENCE
. TABLE
. INDEX
. VIEW
. MATERIALIZED VIEW
. FUNCTION
. PROCEDURE
. TRIGGER
. PACKAGE

== Migration Tools

The application includes several tools to help manage and review migrations.

=== DDL Caching

AI-generated DDL (for missing dependency tables) is automatically cached to reduce API calls and provide an audit trail.

**Dual Storage:**

* **Database cache** - Automatic reuse during validation
* **File storage** - Human-reviewable files in `ai_generated_ddl/` folder per session

**API Endpoints:**

[source,bash]
----
# View cache statistics
curl http://localhost:8000/api/client/1/ddl_cache/stats

# Clear cache for a client
curl -X DELETE http://localhost:8000/api/client/1/ddl_cache

# List AI-generated DDL files for a session
curl http://localhost:8000/api/session/5/generated_ddl
----

=== Migration Reports

Generate AsciiDoc reports summarizing migration results for stakeholders.

**Report Contents:**

* Executive summary (status, success rate, duration)
* Object summary by type (TABLE, VIEW, INDEX, PROCEDURE, etc.)
* File details with validation status
* Error details for failed objects
* Metadata (AI provider, model, timestamps)

**API Endpoints:**

[source,bash]
----
# Get report for a session (returns AsciiDoc)
curl http://localhost:8000/api/session/5/report

# Download as .adoc file
curl -O http://localhost:8000/api/session/5/report/download

# Get report for latest migration (optionally save to file)
curl "http://localhost:8000/api/client/1/migration_report?save=true"
----

=== Rollback Scripts

Automatically generated DROP statements to undo a migration if needed.

**Features:**

* Generated after successful migration
* Objects dropped in reverse dependency order (triggers first, tables last)
* Includes header with warnings and execution instructions
* Preview before executing

**API Endpoints:**

[source,bash]
----
# Get rollback script content
curl http://localhost:8000/api/session/5/rollback

# Preview what will be dropped (dry-run)
curl http://localhost:8000/api/session/5/rollback/preview

# Download as .sql file
curl -O http://localhost:8000/api/session/5/rollback/download

# Execute rollback (requires confirmation)
curl -X POST http://localhost:8000/api/session/5/rollback/execute \
  -H "Content-Type: application/json" \
  -d '{"confirm": true}'
----

=== Per-Object Tracking

Individual database objects (tables, views, indexes, etc.) are tracked separately from files, providing granular visibility into migration progress.

**API Endpoints:**

[source,bash]
----
# Get all objects for a session with status
curl http://localhost:8000/api/session/5/objects

# Filter by type or status
curl "http://localhost:8000/api/session/5/objects?type=TABLE&status=validated"

# Get summary counts by type
curl http://localhost:8000/api/session/5/objects/summary

# Get detailed info for a specific object
curl http://localhost:8000/api/object/42

# Get aggregate summary across all sessions for a client
curl http://localhost:8000/api/client/1/objects/summary
----

**Example Summary Response:**

[source,json]
----
{
  "totals": {"total": 20, "validated": 20, "failed": 0},
  "by_type": {
    "TABLE": {"total": 7, "validated": 7, "failed": 0},
    "INDEX": {"total": 11, "validated": 11, "failed": 0},
    "VIEW": {"total": 1, "validated": 1, "failed": 0},
    "PROCEDURE": {"total": 1, "validated": 1, "failed": 0}
  }
}
----

== Output Files

Each migration session creates the following files in `/app/project_data/{client_id}/{session_id}/`:

[source,text]
----
├── output_table.sql           # Ora2Pg DDL export (tables)
├── output_view.sql            # Ora2Pg DDL export (views)
├── output_procedure.sql       # Ora2Pg DDL export (procedures)
├── ai_generated_ddl/          # AI-generated DDL for missing dependencies
│   ├── employees.sql          # CREATE TABLE employees...
│   ├── departments.sql        # CREATE TABLE departments...
│   └── _manifest.json         # Index with metadata
├── migration_report.adoc      # AsciiDoc migration report
└── rollback.sql               # DROP statements to undo migration
----

== Future Enhancements

* **Data Migration:** Extend the one-click workflow to include data migration after DDL is validated
* **Schema Comparison:** Compare source Oracle and target PostgreSQL schemas to verify migration completeness
